# 3차미프 총 정리

### 미프 3-1차

### 배운거

[탐색적 데이터 분석]

1. kdeplot에서 hue옵션을 주면 여러 개의 범주에 따라 그래프를 비교해가면서 볼 수 있다.
2. barh는 범주를 y에 놓고 x에 수치를 막대로 보여주는데, 되게 시각적으로 괜찮다.
3. 각 모델 별로 서로 코드 실행(테스트) 간 영향을 안 주도록 이름을 다르게 설정하는 것이 깔끔한 편이다.

[기본 모델링]

1. SVC라는 머신러닝 분류모델도 있는데, 얘는 하이퍼 파리미터 튜닝 값이 좀 다르다.
- support vector classifier.
- 주로 이진분류이나 다중분류에도 사용.
- 주어진 데이터를 가장 잘 나누는 결 경계를 찾는 것이 주요 목표.
- 결정 경계는 데이터 공간에서 서포트 벡터들과의 거리를 최대화하는 방식으로 생성.

```python
param_grid = {'C': [0.01, 1, 100], 
             'gamma': [0.0001, 0.001, 0.1, 1],
              'kernel': ['linear', 'rbf'] }         
```

c: 오차의 허용정도

gamma : 결정경계의 유연성

kernel : 커널의 종류 지정. linear : 선형 결정 경계, rbf: 비선형 결정 경

1. RF 모델 객체에 feature_importances_찍으면 feature의 중요도가 나온다.
2. **list(x_train)**. 이런식으로 list로 감싸주면 feature이름이 뽑힌다.
3. 데이터프레임 만드는 걸 어렵게 생각하지마라. 
    - 그냥 시리즈나 리스트로 바로 만들어도 되고, 그 시리즈와 리스트로 dict로 만들어서 dataframe을 만들어도된다.
4. data3=data2[['x']] 특정열만 따서 데이터프레임 만들기.

[단계별 모델링]

1. 새로운 feature만들 때 (activity_dynamic) where 보다 map이 시각적으로 훨씬 깔끔하고 직관적이다.
2. 모델 합치기 함수… 고쳐보고 싶다.
- 드디어 고쳤다. 문제는 그거였다. 모델을 만들때는 min-max scale을 했는데, 합치는 함수에서 데이터 가공할 때는 스케일링을 안했다.
1. tqdm을 쓰면 진행률을 볼 수 있다.

### 느낀점

1. 제한 된 시간안에 문제를 해결해 볼려는 노력을 통해 문제해결력을 높일 수 있다.
2. 잘 짜여진 코드, 특히 함수를 보면 감탄이 나고 재밌고, 나도 따라해보고 싶은 욕구가 생긴다. 다음 프로젝트에는 더 많이 따라가보자. 직접 쳐보기도 하면 좋을 것 같다.

### 

### 미프 3-2차

### 새로 배우는 코드

1. sort_index()옵션으로 index로도 sorting이 가능하다.

```python
# Activity 값 별로 개수 세기 (from 문동규님)
activity_counts = train['label'].value_counts().sort_index()
```

### 배운거

1. 뭔가 모델의 인과관계가 확실하면 머신러닝이 딥러닝보다 잘 맞추는 경향이 있는 것 같다.

(문동규님)

1. plotly extpress라는 전문적 시각화 도구도 있다.
2. mice라는 걸로 결측치를 채울 수 있다. 
3. 목차 구성이 너무 깔끔하다. 어저피 test는 train잘 나온 걸로 해보면 되니까, 헷갈리지 않게 아예 뒤에 따로 목차로 빼놨다.
4. lightgbm에 이런 파라미터가 있는지 몰랐다.     
- model = LGBMClassifier(learning_rate = 0.05, n_estimators=500, num_leaves=150, random_state=530)
- 시간이 있을 때 이 파라미터에 대해 추가적으로 공부해보면 좋겠다.

(이상빈님)

1. 언더샘플링. 클래스 불균형이 있을 때 많은 클래스에 있는것을 비복원 추출해서 균혀을 맞추는 방식. 생각보다 문법이 되게 간단한다.

```
from imblearn.under_sampling import RandomUnderSampler

# 언더 샘플링을 위한 객체 생성
undersampler = RandomUnderSampler(random_state=42)

# 언더 샘플링을 적용할 데이터셋과 레이블 준비
x_resampled, y_resampled = undersampler.fit_resample(x_raw, y_raw)
```

1. 하이퍼파라미터 튜닝법 중 optuna가 있다. 이것은 별도의 문서에 정리해보자.

```python
# 1. Define an objective function to be maximized.
def objective(trial):
    # 2. Suggest values of the hyperparameters using a trial object.
    param = {
        'silent': 1,
        'objective': 'binary:logistic',
        'booster': trial.suggest_categorical('booster', ['gbtree', 'gblinear', 'dart']),
        'lambda': trial.suggest_float('lambda', 1e-8, 1.0, log=True),
        'alpha': trial.suggest_float('alpha', 1e-8, 1.0, log=True)
    }
    #XGB모델생성
    model3=XGBClassifier(**param)
    #모델훈련
    model3.fit(x_train,y_train)
    #모델 성능측정
    pred= model3.predict(x_test)
    accuracy=accuracy_score(y_test,pred)

    return accuracy

# 3. Create a study object and optimize the objective function.
study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=10)

#결과 출력.
trial=study.best_trial
print(trial.value)
for key, value in trial.params.items():
  print('{}:{}'.format(key,value))

```

1. 스태킹과 업샙플링도 쓰셨는데, 나중에 한 번 해보면 좋겠다.

### 느낀점

1. 출제자의 지시사항을 잘 들어야한다. 이것은 직장으로 따지면 상사와도 비슷한 것이므로, 집중해서 들어야, 상사의 의도를 알 수 있는 것과 마찬가지이다.
2. 인트로를 집중해서 들었다면, 데이터를 집중해서 살필필요가 있다. 나는 데이터를 충분히 파악하지 못하고 급하게 들어갔다. 무엇보다 가장 중요한, 각 칼럼이 무엇을 의미하는지 찬찬히 살펴봐야한다. 각 feature들의 정확한 의미도 파악하지 못하고 허겁지겁 들어갔고, 오늘 이게 너무 컸다.
3. 2번과 이어지는 것인데 feature를 짜를때는 매우 신중해야한다. 이 feature가 핵심인지 아닌지 다시한 번 확인해 볼 필요가 있다.

### 나의 생각 흐름.

1. 결측치가 눈에 먼저 들어왔다. 먼저 짜르고 해도 크게 문제 되지 않을 것 같아서 짜르고 했다.
: 하지만 정확한 학습 데이터가 많아야, 과적합이 나지 않는다고 생각해서, 추후에 데이터를 보간하기로 했다.
: 각 라벨에서의 평균값으로 결측치를 채우는게 좋다고 생각했고, 나중에 그렇게 했다.
2. 딥러닝 부터 해보기로 생각했다.
3. 3,4,5,6에 해당하는 데이터가 아주적다.
: 현재 1,2,3,4,5를 구별을 못하므로, 최후의 수단으로 데이터 불균형을 맞출필요가 있다.
: 시간이 부족해서 실제로 실천하지는 못했다.
4. 모델 단계화
: 제대로 구분을 못하는 데이터에 대해 단계화가 필요해 보임 : 남은시간을 이거에 쓰겠음.
: 결론적으로 좋지 못한 판단이었다. 무엇보다 딥러닝 단계화에 완성된 코드가 없었고,
2번 째로는 확실한 설계를 해두지 않은 채 진행했다(잘못 될 경우 처음붜 다시 할 위험이)
: 딱 이걸 미리 생각했을 때 프로젝트에는 한정 된 시간이 있으므로, 머신러닝도 한 번쯤은 해보거나, 아니면 데이터 불균형을 맞추는 걸 시도해 볼 필요가 있었다.
: 머신러닝으로 갈거였으면, 단계화를 좀 줄일 필요가 있었다.

### 내가 찾았던 것

- 모델은 누워있기와 앉아있기는 아주 정확히 구분함.
- 자전거에 앉아있기/서서 자전거타기/서있기 를 구분을 못 함.
- 계단내려가기(5)/올라가기(4)/걷기(1)천천히 걷기(3)
- . 각 라벨에서(11개) 각 feature의 평균을 구해봣을 때 과연 어떤 값이 각각의 라벨을 구분할 수 있을지 생각해 보았고...
결론은 1,2/3,4,5//6,7,8,9,10
이렇게 구분하는 모델을 만들었다. 결론적으로 너무많이 복잡했다.
이거는 3단으로 들어가는 모델링이다... 만약에 하다가 안 되면 수정.
: 근데 이렇게 되도 3,4,5는 구분이 매우 어렵다는 문제가 있다.

---